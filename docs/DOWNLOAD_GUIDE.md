# æ¨¡å‹ä¸‹è¼‰æŒ‡å—

## ğŸ“¥ ä¸‹è¼‰ç‹€æ…‹

ç•¶å‰æ­£åœ¨ä¸‹è¼‰ï¼š
- âœ… **Token é©—è­‰**: æˆåŠŸ
- ğŸ”„ **LLaVA-1.5-7B**: ä¸‹è¼‰ä¸­ (~14GB)
- â³ **ScienceQA**: å¾…ä¸‹è¼‰ (~1GB)

---

## ğŸ“Š ä¸‹è¼‰ä¿¡æ¯

### LLaVA-1.5-7B æ¨¡å‹
- **å¤§å°**: ~14GB
- **æ–‡ä»¶æ•¸**: 17 å€‹
- **åŒ…å«**:
  - æ¨¡å‹æ¬Šé‡ (safetensors)
  - Tokenizer
  - Processor (vision + text)
  - é…ç½®æ–‡ä»¶

### ScienceQA è³‡æ–™é›†
- **å¤§å°**: ~1GB
- **Splits**:
  - Train: ~6K samples (with images)
  - Validation: ~1K samples
  - Test: ~2K samples
- **æ ¼å¼**: Images + Multiple choice questions

---

## â±ï¸ é è¨ˆæ™‚é–“

| ç¶²é€Ÿ | é è¨ˆæ™‚é–“ |
|------|---------|
| 100 Mbps | 20-30 åˆ†é˜ |
| 500 Mbps | 5-10 åˆ†é˜ |
| 1 Gbps | 3-5 åˆ†é˜ |

---

## ğŸ” æª¢æŸ¥ä¸‹è¼‰é€²åº¦

### æ–¹æ³• 1: æŸ¥çœ‹è…³æœ¬è¼¸å‡º
ä¸‹è¼‰è…³æœ¬æ­£åœ¨èƒŒæ™¯é‹è¡Œï¼Œæœƒé¡¯ç¤ºé€²åº¦æ¢å’Œç‹€æ…‹è¨Šæ¯ã€‚

### æ–¹æ³• 2: æª¢æŸ¥å¿«å–ç›®éŒ„
```bash
# HuggingFace é è¨­å¿«å–ä½ç½®
ls -lh ~/.cache/huggingface/hub/

# æŸ¥çœ‹å·²ä¸‹è¼‰çš„æ¨¡å‹
ls -lh ~/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/
```

### æ–¹æ³• 3: ç›£æ§ç£ç¢Ÿä½¿ç”¨
```bash
# æŸ¥çœ‹å¿«å–ç›®éŒ„å¤§å°
du -sh ~/.cache/huggingface/

# å³æ™‚ç›£æ§
watch -n 5 'du -sh ~/.cache/huggingface/'
```

---

## âœ… ä¸‹è¼‰å®Œæˆå¾Œ

ä¸‹è¼‰å®Œæˆå¾Œï¼Œä½ æœƒçœ‹åˆ°ï¼š

```
âœ… æ‰€æœ‰ä¸‹è¼‰æˆåŠŸ!

ä¸‹ä¸€æ­¥:
  é‹è¡Œå¯¦é©—: bash run_scienceqa_experiments.sh

ğŸ“ ä¸‹è¼‰ä½ç½®: /home/wayne/.cache/huggingface
```

### é©—è­‰ä¸‹è¼‰

```bash
# é©—è­‰æ¨¡å‹æ–‡ä»¶
python3 -c "
from transformers import AutoProcessor
processor = AutoProcessor.from_pretrained('llava-hf/llava-1.5-7b-hf')
print('âœ… æ¨¡å‹é©—è­‰æˆåŠŸ!')
"

# é©—è­‰è³‡æ–™é›†
python3 -c "
from datasets import load_dataset
ds = load_dataset('derek-thomas/ScienceQA', split='train[:10]')
print(f'âœ… è³‡æ–™é›†é©—è­‰æˆåŠŸ! ({len(ds)} samples)')
"
```

---

## ğŸ”„ é‡æ–°ä¸‹è¼‰

å¦‚æœä¸‹è¼‰ä¸­æ–·æˆ–å¤±æ•—ï¼š

```bash
# é‡æ–°é‹è¡Œä¸‹è¼‰è…³æœ¬ï¼ˆæœƒè‡ªå‹•æ¢å¾©ï¼‰
bash download_models.sh

# æˆ–ä½¿ç”¨ Python è…³æœ¬
python3 download_models.py --token_file ./huggingface_token.txt
```

ä¸‹è¼‰æœƒè‡ªå‹•å¾ä¸­æ–·è™•ç¹¼çºŒï¼Œä¸æœƒé‡è¤‡ä¸‹è¼‰å·²æœ‰æ–‡ä»¶ã€‚

---

## ğŸ—‘ï¸ æ¸…ç†å¿«å–

å¦‚æœéœ€è¦é‡æ–°ä¸‹è¼‰æˆ–æ¸…ç†ç©ºé–“ï¼š

```bash
# åˆªé™¤ç‰¹å®šæ¨¡å‹å¿«å–
rm -rf ~/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/

# åˆªé™¤ç‰¹å®šè³‡æ–™é›†å¿«å–
rm -rf ~/.cache/huggingface/datasets/derek-thomas___science_qa/

# æ¸…ç†æ•´å€‹ HuggingFace å¿«å–ï¼ˆè¬¹æ…ä½¿ç”¨ï¼ï¼‰
rm -rf ~/.cache/huggingface/
```

---

## ğŸ’¾ ç£ç¢Ÿç©ºé–“éœ€æ±‚

### æœ€ä½è¦æ±‚
- æ¨¡å‹: 14GB (LLaVA-1.5-7B)
- è³‡æ–™é›†: 1GB (ScienceQA)
- è¨“ç·´çµæœ: ~5GB (per method)
- **ç¸½è¨ˆ**: ~35GB

### æ¨è–¦
- é ç•™ 50GB+ ç©ºé–“
- è€ƒæ…®å¤šå€‹å¯¦é©—å’Œæ¨¡å‹ç‰ˆæœ¬

---

## ğŸ“ å¿«å–ä½ç½®

HuggingFace ä½¿ç”¨ä»¥ä¸‹å„ªå…ˆé †åºæ±ºå®šå¿«å–ä½ç½®ï¼š

1. `HF_HOME` ç’°å¢ƒè®Šæ•¸
2. `XDG_CACHE_HOME/huggingface` (Linux)
3. `~/.cache/huggingface` (é è¨­)

### è‡ªå®šç¾©å¿«å–ä½ç½®

```bash
# è¨­å®šç’°å¢ƒè®Šæ•¸ï¼ˆè‡¨æ™‚ï¼‰
export HF_HOME=/path/to/custom/cache
python3 download_models.py

# æ°¸ä¹…è¨­å®šï¼ˆåŠ å…¥ ~/.bashrcï¼‰
echo 'export HF_HOME=/path/to/custom/cache' >> ~/.bashrc
source ~/.bashrc
```

æˆ–ä½¿ç”¨è…³æœ¬åƒæ•¸ï¼š

```bash
python3 download_models.py --cache_dir /path/to/custom/cache
```

---

## ğŸŒ ç¶²è·¯å•é¡Œ

### é€£ç·šå•é¡Œ
å¦‚æœé‡åˆ°é€£ç·šéŒ¯èª¤ï¼š

```bash
# ä½¿ç”¨é¡åƒç«™ï¼ˆä¸­åœ‹å¤§é™¸ç”¨æˆ¶ï¼‰
export HF_ENDPOINT=https://hf-mirror.com
python3 download_models.py
```

### ä»£ç†è¨­å®š
```bash
# HTTP/HTTPS ä»£ç†
export HTTP_PROXY=http://proxy.example.com:8080
export HTTPS_PROXY=http://proxy.example.com:8080
python3 download_models.py
```

---

## ğŸ“‹ ä¸‹è¼‰å…¶ä»–æ¨¡å‹/è³‡æ–™é›†

### ä¸‹è¼‰æ›´å¤šæ¨¡å‹

```bash
# LLaVA-1.5-13B (æ›´å¤§çš„æ¨¡å‹)
python3 download_models.py \
  --models llava-hf/llava-1.5-13b-hf

# åŒæ™‚ä¸‹è¼‰å¤šå€‹æ¨¡å‹
python3 download_models.py \
  --models \
    llava-hf/llava-1.5-7b-hf \
    llava-hf/llava-1.5-13b-hf
```

### ä¸‹è¼‰å…¶ä»– VLM è³‡æ–™é›†

```bash
# A-OKVQA
python3 download_models.py \
  --skip_models \
  --datasets HuggingFaceM4/A-OKVQA

# ChartQA
python3 download_models.py \
  --skip_models \
  --datasets ahmed-masry/ChartQA
```

---

## ğŸš¨ å¸¸è¦‹å•é¡Œ

### Q1: ä¸‹è¼‰é€Ÿåº¦å¾ˆæ…¢
**A**:
- æª¢æŸ¥ç¶²è·¯é€£ç·š
- è€ƒæ…®ä½¿ç”¨é¡åƒç«™ï¼ˆè¦‹ä¸Šæ–¹ï¼‰
- å˜—è©¦åœ¨éé«˜å³°æ™‚æ®µä¸‹è¼‰

### Q2: ç£ç¢Ÿç©ºé–“ä¸è¶³
**A**:
- æ¸…ç†ä¸éœ€è¦çš„å¿«å–
- æ›´æ”¹å¿«å–ä½ç½®åˆ°æ›´å¤§çš„ç£ç¢Ÿ
- åªä¸‹è¼‰å¿…è¦çš„æ¨¡å‹

### Q3: Token é©—è­‰å¤±æ•—
**A**:
- æª¢æŸ¥ token æ–‡ä»¶å…§å®¹æ˜¯å¦æ­£ç¢º
- ç¢ºèª token æ²’æœ‰éæœŸ
- è¨ªå• https://huggingface.co/settings/tokens é‡æ–°ç”Ÿæˆ

### Q4: ä¸‹è¼‰ä¸­æ–·
**A**:
- é‡æ–°é‹è¡Œè…³æœ¬ï¼ˆæœƒè‡ªå‹•æ¢å¾©ï¼‰
- HuggingFace Hub æ”¯æ´æ–·é»çºŒå‚³
- ä¸æœƒé‡è¤‡ä¸‹è¼‰å·²æœ‰æ–‡ä»¶

---

## ğŸ“ éœ€è¦å¹«åŠ©ï¼Ÿ

- HuggingFace Hub æ–‡æª”: https://huggingface.co/docs/hub
- LLaVA é …ç›®: https://github.com/haotian-liu/LLaVA
- ScienceQA è³‡æ–™é›†: https://huggingface.co/datasets/derek-thomas/ScienceQA

---

**ç‹€æ…‹**: ğŸ”„ ä¸‹è¼‰é€²è¡Œä¸­
**æœ€å¾Œæ›´æ–°**: 2025-10-28
